<html>

<head>
    <meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
    <link rel="stylesheet" type="text/css" href="style.css" />
    <title>Feiyang YE</title>
    <base href="https://Feiyang-YE.github.io/index.html">
</head>

<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<h1 style="padding-left: 0.5em">Feiyang YE</h1><hr>
<td id="layout-menu">
    <div class="menu-item"><a href="index.html" class="current">Home</a></div>

</td>
<td id="layout-content">

    <h1 style="margin-top: 0em">Home</h1><br>
  <!--  <p>[ <a href="#news">News</a>,
        <a href="#interest">Research Interests</a>,
        <a href="#job">Job Experience</a>,
        <a href="#edu">Education</a> ]</p>-->

    <table class="imgtable"><tr valign="top">
        <!--<td><img src="xingruiyu.jpg" alt="xxxx" /></td>-->
        <td align="left">
            <p><span style="font-size: 110%"><b>Feiyang YE</b></span></p>
            <p>
                Ph.D. student<br>
                <a href="https://www.uts.edu.au/research-and-teaching/our-research/australian-artificial-intelligence-institute">University of Technology Sydney (UTS)</a>
            </p>

            <p>
                E-mail: yefeiyang123@live.com<br>
                <a href="https://scholar.google.com/citations?user=3EX25cAAAAAJ" target="_blank">[Google Scholar]</a>
            </p>
        </td>
    </tr></table>

	   <div>
        <h2><hr><a name="biography"></a>Brief Biography</h2>
        <ul>
          I am currently a fourth-year Ph.D. student at Australian Artificial Intelligence Institute (AAII) in University of Technology Sydney(UTS), supervised by <a href="https://scholar.google.com.sg/citations?user=rJMOlVsAAAAJ" target="_blank"> 
		  Prof. Ivor W Tsang </a> and <a href="https://yuzhanghk.github.io/" target="_blank"> Prof. Yu Zhang</a>. 
		I got my B.S. degree in Mathematics and Applied Mathematics from Southern University of Science and Technology in 2018 and my M.S. degree in Computational Mathematics from Harbin Institute of Technology in 2020.
		My research interests include Machine Learning, and optimization, especially in multi-task learning, meta-learning, and black-box optimization.
		
		
		<br /><br />
		<br />News:
                  <br />
		2024.01: One paper got accepted by ICLR 2024.
		 
	
        </ul>
    </div>
	
	

	
	 <div>
        <h2><hr><a name="publications"></a>Submissions Under Review/Revision</h2>
        <ul>
            
               <li><p> “  Black-box Generalization of Machine Teaching,” 
		 <br />      X. Cao, Y. Guo,   I. W. Tsang, and James T. Kwok, 
		 <br /> <i> Journal of Machine Learning Research, review.   </p></li>
 
		<li><p> “A Survey of Learning on Small Data,” 
			 <br /> X. Cao, W. Bu, J. Huang, Y. Chang, and I. W. Tsang, 
		 <br />	<i>   ACM Computing Surveys, review.  </p></li>
		 
		 
		
		
    </div>
	

	<div>
        <h2><hr><a name="publications"></a>Publications</h2>
			<ul>
                <li><p> Preprints: </p></li>
					<ul>
						<li><p> <b>Yueming Lyu</b> and Ivor W. Tsang. <a href="https://arxiv.org/pdf/2106.06097.pdf" target="_blank"> Neural Optimization Kernel: Towards Robust Deep Learning</a>.   <i>Preprint</i>. </p></li>
						<li><p> <b>Yueming Lyu</b>, Yuan Yuan and Ivor W. Tsang. <a href="https://arxiv.org/pdf/2011.06446.pdf" target="_blank">Subgroup-based Rank-1 Lattice Quasi-Monte Carlo</a>.  <i>Conference on Neural Information Processing Systems</i> (NeurIPS), 2020 </p></li>
						<li><p> <b>Yueming Lyu</b>. <a href="http://proceedings.mlr.press/v70/lyu17a/lyu17a.pdf" target="_blank">Spherical structured feature maps for kernel approximation</a>. In <i>International Conference on Machine Learning</i> (ICML), 2017</p></li>
						
					</ul>
                <li><p> Conference Papers: </p></li>
					<ul>
						<li><p> Feiyang Ye<sup>*</sup>, <b>Yueming Lyu<sup>*</sup> </b>, Xuehao Wang, Yu Zhang, Ivor W. Tsang. Adaptive Stochastic Gradient Algorithm for Black-box Multi-Objective Learning.  Accepted In <i> International Conference on Learning Representations</i> (ICLR), 2024</p></li>
						<li><p> <b>Yueming Lyu</b>. <a href="https://openreview.net/pdf?id=M8CYKLHoEN" target="_blank">Fast Rank-1 Lattice Targeted Sampling for Black-box Optimization</a>.  In <i>Conference on Neural Information Processing Systems</i> (NeurIPS), 2023</p></li>
						<li><p> Jing Li, Yuangang Pan, <b>Yueming Lyu</b>, Yinghua Yao, Yulei Sui, Ivor W. Tsang <a href="https://arxiv.org/pdf/2304.14831.pdf" target="_blank">Earning Extra Performance from Restrictive Feedbacks</a>. <i>IEEE Transactions on Pattern Analysis and Machine Intelligence </i> (TPAMI) </p></li>
						<li><p> <b>Yueming Lyu</b> and Ivor W. Tsang. <a href="https://arxiv.org/pdf/1910.04301.pdf" target="_blank">Black-box Optimizer with Implicit Natural Gradient</a>. In <i>European Conference on Machine Learning</i>. (ECML), 2021 </p></li>
						<li><p> <b>Yueming Lyu</b>, Yuan Yuan and Ivor W. Tsang. <a href="https://arxiv.org/pdf/1905.10041.pdf" target="_blank">Efficient Batch Black-box Optimization with Deterministic Regret Bounds</a>.  <i>Preprint</i>. </p></li>
						<li><p> Xingrui Yu, <b>Yueming Lyu</b> and Ivor W. Tsang. <a href="https://arxiv.org/pdf/2006.15061.pdf" target="_blank">Intrinsic Reward Driven Imitation Learning via Generative Model</a>. In <i>International Conference on Machine Learning</i> (ICML), 2020</p></li>
					</ul>
		<li><p> Journal Papers: </p></li>
					<ul>
						<li><p> Feng Hong, Jiangchao Yao, <b>Yueming Lyu</b>, Zhihan Zhou, Ivor Tsang, Ya Zhang, Yanfeng Wang. On Harmonizing Implicit Subpopulations.  Accepted In <i> International Conference on Learning Representations</i> (ICLR), 2024</p></li>
						<li><p> <b>Yueming Lyu</b> and Ivor W. Tsang. <a href="https://openreview.net/pdf?id=rkgt0REKwS" target="_blank">Curriculum Loss: Robust Learning and Generalization against Label Corruption</a>. In <i> International Conference on Learning Representations</i> (ICLR), 2020</p></li>
						<li><p> Yuan Yuan, <b>Yueming Lyu</b>, Xi Shen, Ivor W. Tsang, Dit-Yan Yeung.  <a href="https://openreview.net/pdf?id=HkljioCcFQ" target="_blank">Marginalized average attentional network for weakly-supervised learning</a>. In  International Conference on Learning Representations (ICLR), 2019 </p></li>
						
					</ul>
            </ul>
    </div>
	
	
	
	
    

    <div>
        <h2><hr><a name="service"></a>Professional Service</h2>
            <ul>

                <li><p> Journal Reviewer: </p></li>
					<ul>
						<li><p> IEEE Transactions on Pattern Analysis and Machine Intelligence (T-PAMI) </p></li>
					</ul>
            </ul>
    </div>


    <div>
        <h2><hr><a name="work"></a>Work</h2>
            <ul>
                <li><p>   Agency for Science, Technology and Research (A*STAR), Research Intern. 2022.8-2023.8 </p></li>
		    
		  <li><p>  HUAWEI 2012 Laboratory, Research Intern. 2019.12- 2020.2.  </p></li>
            </ul>
    </div>
		 
		 
		 
		  <div>
        <h2><hr><a name="teaching"></a>Teaching</h2>
            <ul>
                <li><p>  Advanced Artificial Intelligence, Teaching assistant. Spring 2024, SUSTech.</p></li>
		  <li><p>	 Advanced Artificial Intelligence, Teaching assistant. Spring 2021, SUSTech. </p></li>
		    <li><p>	 Linear Algebra, Teaching assistant. Fall 2019, SUSTech. </p></li>
		      <li><p>	 ALinear Algebra, Teaching assistant. Fall 2019, SUSTech. </p></li>
		  
            </ul>
    </div>

 


</td>
</tr>
</table>
</body>
</html>
